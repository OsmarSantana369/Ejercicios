---
title: "Regresión lineal múltiple"
author: "Osmar Dominique"
date: "2025-09-18"
output: html_document
---

Veamos un ejemplo con la data "iris"

```{r, echo=FALSE}
datos <- iris
datos1 <- datos[,1:4]

plot(datos)
```

Veamos una regresión lineal múltiple entre estas variables. Para ello consideremos:

-   Variable de respuesta (dependiente): Ancho del pétalo.
-   Variables explicativas (independientes): Largo del pétalo, largo de sépalo, ancho de sépalo.

```{r, echo=FALSE}
#Modelo de regresión lineal múltiple
modelo <- lm(Petal.Width ~ Petal.Length + Sepal.Width + Sepal.Length, data = datos) #lineal simple
summary(modelo)
```

Observamos que las tres variables son significativas para el modelo, el único que no lo es es el intercepto.

$$ y = 0 + 0.52408*Petal.Lenght + 0.22283*Sepal.Width - 0.20727*Sepal.Length $$

Del resumen del modelo obtenemos un coeficiente de determinación ajustado ($R^2$ ajustado) de 0.9366, es decir, el modelo explica el 93.66% de la variabilidad total.

## ANOVA

```{r, echo=FALSE}
anova(modelo)
```

Del anova, obtenemos un p-value menor a 0.05 para las tres variables por lo que se rechaza H0 en favor de H1, es decir, el modelo sí es significativo para las tres variables.

Entonces estamos en la posibilidad de hacer predicciones.

```{r, echo=FALSE}
nuevo <- data.frame(Petal.Length = 5.1, Sepal.Width = 3.5, Sepal.Length = 1.4)
predict(object=modelo, newdata=nuevo, interval="confidence", level=0.95)
predict(object=modelo, newdata=nuevo, interval="prediction", level=0.95)
```

Ahora lo interesante es observar cuál es el mejor modelo para la variable de respuesta (una sola variable, con dos variables o tres variables).

# Comparación de modelos

* Modelo 1 con las tres variables 

```{r, echo=FALSE}
modelo1 <- lm(Petal.Width ~ Petal.Length + Sepal.Width + Sepal.Length, data = datos) #lineal simple
summary(modelo1)
```

* Modelo 2 con dos variables (sin longitud del pétalo)

```{r, echo=FALSE}
modelo2 <- lm(Petal.Width ~ Sepal.Width + Sepal.Length, data = datos) #lineal simple
summary(modelo2)
```

* Comparemos el Modelo 1 vs el Modelo 2

```{r, echo=FALSE}
anova(modelo1, modelo2)
```

Con esta ANOVA estamos analizando si es mejor opción agregar una variable más al modelo.

Si p-value < 0.05 entonces nos dice que el modelo será mejor con más variables.

Si p-value >= 0.05 entonces el mejor modelo es el que tiene menos variables.

Como p-value = $2.2*10^{-16}$, entonces el mejor modelo es el 1.

* Modelo 3 con dos variables (sin ancho del sépalo)

```{r, echo=FALSE}
modelo3 <- lm(Petal.Width ~ Petal.Length + Sepal.Length, data = datos) #lineal simple
summary(modelo3)
```

Ahora comparemos el Modelo 1 vs el Modelo 3

```{r, echo=FALSE}
anova(modelo1, modelo3)
```

* Modelo 4 con una variable 

```{r, echo=FALSE}
modelo4 <- lm(Petal.Width ~ Petal.Length, data = datos) #lineal simple
summary(modelo4)
```

Ahora comparemos el Modelo 1 vs el Modelo 3

```{r, echo=FALSE}
anova(modelo3, modelo4)
```

Al observar el p-value = 0.04827 notamos que la variable longitud del sépalo, ya no aporta mucho al modelo. Por lo que podriamos quedarnos con el modelo de una sola variable.

Hasta aqui notamos que los mejores modelos son con una variable (longitud del pétalo) o con las tres variables.

* Comparemos el Modelo 1 vs el Modelo 4

```{r, echo=FALSE}
anova(modelo1, modelo4)
```

Como conclusión, conviene usar más el modelo de 3 variables.

# Predicciones

5.1 long sepalo
3.5 ancho sepalo
1.4 long petalo
0.2 ancho petalo (variable de respuesta)

```{r, echo=FALSE}
nuevo <- data.frame(Petal.Length = 5.1)
predict(object=modelo4, newdata=nuevo, interval="confidence", level=0.95)
predict(object=modelo4, newdata=nuevo, interval="prediction", level=0.95)
```
Con el modelo 1 se obtiene una predicción de 2.922244, mientras que con el modelo 4 es de 1.757277.

# Análisis de residuos (supuestos del modelo)

```{r, echo=FALSE}
residuos <- rstandard(modelo)   #Los errores en las predicciones
valores.ajustados <- fitted(modelo)   #Predicciones dada por el modelo
```

Vamos a verificar si se cumplen los tres supuestos del modelo.

# Prueba de independencia

Aquí probamos las hipótesis

$H_0$: Los datos no son independientes

$H_1$: Los datos son independientes

De la prueba obtenenmos un p-value = 0.00056, por lo que rechazamos $H_0$. Así los datos son independientes.

```{r, message=FALSE, echo=FALSE}
library(lmtest)
dwtest(modelo)
plot(modelo$residuals) 
```

# Prueba de homocedasticidad (varianza constante)

Vamos a probar las hipótesis:

$H_0$ La varianza es constante.

$H_1$ La varianza no es constante.

De la prueba obtenemos un p-value de 0.29569, entonces se acepta $H_0$, por lo que la varianza es constante.

```{r, echo=FALSE, message=FALSE}
plot(valores.ajustados, residuos) #manera gráfica
library(car)
ncvTest(modelo)
```

# Normalidad

Vamos a probar las hipótesis:

$H_0$ Los errores están distribuidos de manera normal.

$H_1$ No se cumple el supuesto de normalidad.

De la prueba obtenemos un p-value de 0.739, entonces no se puede rechazar $H_0$, por lo que podemos decir que los errores están distribuidos de manera normal.

```{r, echo=FALSE}
qqnorm(residuos)
qqline(residuos)
shapiro.test(residuals(modelo))
```

Con esto podemos concluir que del modelo se cumplen los supuestos: normalidad e independencia y varianza constante.



















