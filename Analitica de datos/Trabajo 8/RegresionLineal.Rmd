---
title: "Regresión lineal"
author: "Osmar Dominique"
date: "2025-09-10"
output: html_document
---

Veamos un ejemplo con la data "iris".

```{r, echo=FALSE}
datos <- iris
datos1 <- datos[,1:4]
```

Para ver si hay una buena relación entre al menos dos variables de la base de datos, obtenemos la matriz de covarianzas o la matriz de correlaciones.

```{r}
cor(datos1)
```

De la matriz, observamos que la relacion más grande que tenemos es: **ancho del pétalo** y **largo del pétalo**.

Obtengamos su diagrama de dispersión de estas dos variables.

```{r}
plot(x = datos$Petal.Length, y = datos$Petal.Width)
```

Veamos ahora una regresión lineal entre estas variables. Para ello consideremos:

* Variable de respuesta (dependiente): ancho del pétalo.
* Variable explicativa (independiente): largo del pétalo.

Obtengamos la recta de regresión lineal de Y sobre X

```{r}
modelo <- lm(datos$Petal.Width ~ datos$Petal.Length, data = datos) #lineal simple
summary(modelo) #resumen del modelo 
```

* Recta de regresión lineal

```{r}
modelo$coefficients
```

Con los valores estimados podemos obtener la recta

$$ y = -0.363076 + 0.415755*X $$

Ahora, veamos si los coeficientes del modelo son significativos. Esto lo haremos mediante pruebas de hipótesis.

Del resumen del modelo, tenemos lo siguiente:

* Para $ \beta_0 $ (intercepto), su p-value es $ 4.7*10^{-16} $.
* Para $ \beta_1 $ (pendiente), su p-value es $ 2*10^{-16} $.

En los dos p-values, obtenemos valores menores a 0.05, por lo que rechazamos H0 en favor de H1, es decir, que los dos coeficientes deben ser distintos de cero. Por lo tanto, **los dos coeficientes son significativos para el modelo**.

**Conclusión:** Como los dos coeficientes son significativos, entonces nuestro modelo sí queda representado como:

$$ y = -0.363076 + 0.415755*X $$

Del resumen del modelo, obtenemos un coeficiente de determinación ($ R^2 $) de 0.9271, es decir, el modelo explica el 92.7% da la variabilidad total.

## ANOVA

Este nos servirá para decir si el modelo es significativo o no.

```{r}
#ANOVA en regresión lineal
anova(modelo)
```

Del ANOVA obtenemos un p-value = 2.2e-16, entonces se rechaza H0, en favor de H1, es decir, que el modelo sí es significativo.

Entonces estamos en la posibilidad de poder hacer predicciones

## PREDICCIONES

```{r}
#predicciones 
#Con los coeficientes dados, se puede sustituir el valor deseado.
nuevo <- data.frame(datos$Petal.Length = 1.35)
predict(object=modelo, newdata=nuevo, interval="confidence", level=0.95)
predict(object=modelo, newdata=nuevo, interval="prediction", level=0.95)
```



**NOTA:** Recordemos que toda prueba de hipótesis debe contener:

H0: Hipótesis nula.
H1: Hipótesis alterntiva (es lo que el investigador afirma). 

Posteriormente se calcula un estadístico y se obtiene un p-value (valor-p), el cual nos dirá si se rechaza H0 o no habrá evidencia para poder echazar H0.

Si tenemos una significancia $\alpha$ (comunmente 0.05). Entonces tenemos:
Si p-value < $ \alpha $, entonces se rechaza H0 en favor de H1. En caso contrario, no hay evidencia para rechazar H0.















